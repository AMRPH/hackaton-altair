{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "        .master(\"local[6]\")\n",
    "        .appName('PySpark_Prepare')\n",
    "        .config(\"spark.driver.memory\", \"15g\")\n",
    "        .getOrCreate())\n",
    "\n",
    "dataset_schema = [\n",
    "    T.StructField('slctn_nmbr', T.IntegerType(), True),\n",
    "    T.StructField('client_id', T.StringType(), True),\n",
    "    T.StructField('npo_account_id', T.StringType(), True),\n",
    "    T.StructField('npo_accnts_nmbr', T.IntegerType(), True),\n",
    "    T.StructField('pmnts_type', T.IntegerType(), True),\n",
    "    T.StructField('year', T.IntegerType(), True),\n",
    "    T.StructField('quarter', T.StringType(), True),\n",
    "    T.StructField('gender', T.IntegerType(), True),\n",
    "    T.StructField('age', T.IntegerType(), True),\n",
    "    T.StructField('clnt_cprtn_time_d', T.IntegerType(), True),\n",
    "    T.StructField('actv_prd_d', T.IntegerType(), True),\n",
    "    T.StructField('lst_pmnt_rcnc_d', T.IntegerType(), True),\n",
    "    T.StructField('balance', T.FloatType(), True),\n",
    "    T.StructField('oprtn_sum_per_qrtr', T.FloatType(), True),\n",
    "    T.StructField('oprtn_sum_per_year', T.FloatType(), True),\n",
    "    T.StructField('frst_pmnt_date', T.StringType(), True),\n",
    "    T.StructField('lst_pmnt_date_per_qrtr', T.IntegerType(), True),\n",
    "    T.StructField('frst_pmnt', T.FloatType(), True),\n",
    "    T.StructField('lst_pmnt', T.FloatType(), True),\n",
    "    T.StructField('pmnts_sum', T.FloatType(), True),\n",
    "    T.StructField('pmnts_nmbr', T.IntegerType(), True),\n",
    "    T.StructField('pmnts_sum_per_qrtr', T.FloatType(), True),\n",
    "    T.StructField('pmnts_sum_per_year', T.FloatType(), True),\n",
    "    T.StructField('pmnts_nmbr_per_qrtr', T.IntegerType(), True),\n",
    "    T.StructField('pmnts_nmbr_per_year', T.IntegerType(), True),\n",
    "    T.StructField('incm_sum', T.FloatType(), True),\n",
    "    T.StructField('incm_per_qrtr', T.FloatType(), True),\n",
    "    T.StructField('incm_per_year', T.FloatType(), True),\n",
    "    T.StructField('mgd_accum_period', T.FloatType(), True),\n",
    "    T.StructField('mgd_payment_period', T.FloatType(), True),\n",
    "    T.StructField('phone_number', T.IntegerType(), True),\n",
    "    T.StructField('email', T.IntegerType(), True),\n",
    "    T.StructField('lk', T.IntegerType(), True),\n",
    "    T.StructField('assignee_npo', T.IntegerType(), True),\n",
    "    T.StructField('assignee_ops', T.IntegerType(), True),\n",
    "    T.StructField('postal_code', T.StringType(), True),\n",
    "    T.StructField('region', T.StringType(), True),\n",
    "    T.StructField('citizen', T.IntegerType(), True),\n",
    "    T.StructField('fact_addrss', T.IntegerType(), True),\n",
    "    T.StructField('appl_mrkr', T.IntegerType(), True),\n",
    "    T.StructField('evry_qrtr_pmnt', T.IntegerType(), True),\n",
    "    T.StructField('churn', T.IntegerType(), True)\n",
    "]\n",
    "\n",
    "dataset_struct = T.StructType(fields=dataset_schema)\n",
    "\n",
    "dataset = spark.read.csv('dataset/train.csv', sep=',', header=True, schema=dataset_struct)\n",
    "# удаляем ненужные параметры\n",
    "dataset = dataset.drop(*['oprtn_sum_per_year', 'frst_pmnt_date', 'lst_pmnt_date_per_qrtr', 'pmnts_sum_per_year',\n",
    "                        'pmnts_nmbr_per_year', 'incm_per_year', 'postal_code', 'npo_accnts_nmbr',\n",
    "                        'slctn_nmbr', 'client_id'])\n",
    "dataset = dataset.dropDuplicates()\n",
    "dataset = dataset.dropna()\n",
    "# сортируем\n",
    "dataset = dataset.sort(['npo_account_id', 'quarter'])\n",
    "\n",
    "lag = 8\n",
    "# данные для обогощения датасета\n",
    "data_cntrbtrs = pl.read_csv('dataset/cntrbtrs.csv', separator=';')\n",
    "region_encoder = pl.read_csv('dataset/region_encoder.csv')\n",
    "gdp = pl.read_csv('dataset/gdp.csv')\n",
    "mrot = pl.read_csv('dataset/mrot.csv')\n",
    "usd = pl.read_csv('dataset/usd.csv')\n",
    "\n",
    "# оставляем только счета с > 8 записями\n",
    "filter_ids = dataset.groupBy('npo_account_id').count().withColumnRenamed('count', 'lag')\n",
    "filter_ids = filter_ids.filter(filter_ids.lag >= lag+1).select('npo_account_id')\n",
    "ids = np.array(filter_ids.collect()).reshape(-1)\n",
    "\n",
    "dataset_pl = pl.from_pandas(dataset.toPandas())# 80% времени выполняется эта строчка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# кодирование региона\n",
    "def get_region(region):\n",
    "    region = region.split(' ')[0]\n",
    "    new_value = region_encoder.filter(pl.col('region') == region)['value'][0]\n",
    "    return new_value\n",
    "\n",
    "# значение мрот\n",
    "def get_mrot(year):\n",
    "    new_value = mrot.filter(pl.col('year') == year)['rubles'][0]\n",
    "    return int(new_value)\n",
    "\n",
    "# значение ввп\n",
    "def get_gdp(year):\n",
    "    new_value = gdp.filter(pl.col('year') == year)['rubles'][0]\n",
    "    return int(new_value)\n",
    "\n",
    "# значение курса доллара\n",
    "def get_usd(quarter):\n",
    "    new_value = usd.filter(pl.col('quarter') == quarter)['rubles'][0]\n",
    "    return new_value\n",
    "\n",
    "# тип пенсионного вклада\n",
    "def get_pens_type(id):\n",
    "    value = data_cntrbtrs.filter(pl.col('npo_accnt_id') == id)['accnt_pnsn_schm'][0]\n",
    "    return value\n",
    "\n",
    "\n",
    "new_dataset = []\n",
    "for i in range(len(ids)):\n",
    "    id = ids[i]\n",
    "    dataset_id = dataset_pl.filter(pl.col('npo_account_id') == id) # берем записи конкретного счета\n",
    "    dataset_id = dataset_id.drop('npo_account_id')\n",
    "\n",
    "    target = dataset_id.tail(1)['churn'][0]# сохраняем таргет и тип вклада\n",
    "    pens = get_pens_type(id)\n",
    "\n",
    "    dataset_id = dataset_id.drop('churn')\n",
    "    dataset_id = dataset_id.slice(len(dataset_id)-lag-1, lag)# оставляем последние 8 отчетов\n",
    "\n",
    "    dataset_id = dataset_id.with_columns(pl.col('region')\n",
    "                                        .map_elements(lambda x: get_region(x), return_dtype=pl.Float64)\n",
    "                                        .alias('region'))# кодируем регион\n",
    "    \n",
    "    dataset_id = dataset_id.with_columns(pl.col('year')\n",
    "                                        .map_elements(lambda x: get_mrot(x), return_dtype=pl.Int64)\n",
    "                                        .alias('mrot'))# добавляем мрот\n",
    "    \n",
    "    dataset_id = dataset_id.with_columns(pl.col('year')\n",
    "                                        .map_elements(lambda x: get_gdp(x), return_dtype=pl.Int64)\n",
    "                                        .alias('gdp'))# добавляем ввп\n",
    "    \n",
    "    \n",
    "    dataset_id = dataset_id.with_columns(pl.col('quarter')\n",
    "                                        .map_elements(lambda x: get_usd(x), return_dtype=pl.Float64)\n",
    "                                        .alias('usd'))# добавляем курс доллара\n",
    "    dataset_id = dataset_id.with_columns(pl.col('quarter')\n",
    "                                        .map_elements(lambda x: int(x[5:6]), return_dtype=pl.Int64)\n",
    "                                        .alias('quarter'))\n",
    "    dataset_id = dataset_id.drop('year')\n",
    "\n",
    "    sample = np.append(dataset_id.to_numpy().reshape(-1), (pens, target))# формируем сэмпл\n",
    "    new_dataset.append(sample)\n",
    "np.save('dataset_train_prepared.npy', np.array(new_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
